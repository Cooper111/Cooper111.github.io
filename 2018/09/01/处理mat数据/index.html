<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>处理mat数据 | Cooper111&#39;s Blog</title>
  <meta name="description" content="A lazy student." />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />

  <meta name="generator" content="Cooper111's Blog">

  
  
  

  
</head>


<body class="post-template">

  <header class="site-head"  style="background-image: url(//blog.ghost.org/content/images/2013/Nov/cover.png)" >
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="//blog.ghost.org/content/images/2013/Nov/bloglogo_1-1.png" alt="Blog Logo"/></a> 
            <h1 class="blog-title">Cooper111's Blog</h1>
            <h2 class="blog-description">A lazy student.</h2>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2018-08-31T16:31:01.000Z" itemprop="datePublished">
          2018-09-01
      </time>
    
</span>
    <h1 class="post-title">处理mat数据</h1>
    <section class="post-content">
      <p>解析原mat的索引，分割训练和测试制作新mat</p>
<pre>
# -*- coding: utf-8 -*-
"""
Created on Sun Jul  1 15:55:32 2018


HSGAN dataset:
Semisupervised Hyperspectral Image Classification Based on Generative Adversarial Networks

Dataset: Indian Pines data set
    IndiaP.mat

@author: FeiDong
"""
import numpy as np
import scipy.io as scio
import matplotlib.pyplot as plt
import math
from sklearn.cross_validation import train_test_split
# =============================================================================
# read dataset and convert
dataset_path = './dataset/IndiaP.mat'
data_mat = scio.loadmat(dataset_path)

img = np.array(data_mat['img']) # read data from dict
GroundT = np.array(data_mat['GroundT']).T # read data from dict
data_G_img = np.zeros((GroundT.shape[0], img.shape[2])) # 存放提取的具有标签的img

for i in range(GroundT.shape[0]):
    temp_index = GroundT[i, 0]
    if temp_index % img.shape[0] != 0 :
        temp_col = math.floor(temp_index / img.shape[0])
        temp_row = int(math.fmod(temp_index, img.shape[0]) - 1)
    else:
        temp_col = math.floor(temp_index / img.shape[0])-1
        temp_row = int(img.shape[0] - 1)

    data_G_img[i, :] = img[temp_col, temp_row, :]

# 每一行是一个样本，第1列为索引值，第2列为标签，之后200列为像元信息.
data_sample = np.hstack((GroundT, data_G_img)) 
# 每一行是一个样本，第1列为索引值，第2列为标签.
data_sample_label = data_sample[:, [0,1]]   
# 每一行是一个样本，第1列为索引值，之后200列为像元信息.
data_sample_dataset = data_sample
data_sample_dataset = np.delete(data_sample, [1], axis=1)   

# 随机划分为训练子集和测试子集
x_trainI, x_testI, y_trainI, y_testI = train_test_split(
        data_sample_dataset,data_sample_label,test_size=0.1, random_state=1)
# 提取出训练样本和测试样本的索引
x_train_index = x_trainI[:, 0]
x_test_index = x_testI[:, 0]
# 剔除样本中的index
x_train = x_trainI[:, 1:201]
x_test = x_testI[:, 1:201]
y_train = y_trainI[:, 1][:, np.newaxis]
y_test = y_testI[:, 1][:, np.newaxis]

# save data_sample
data_sample_path = './dataset/data_sample.mat'
scio.savemat(data_sample_path, {'data': data_sample,
                               'x_train': x_train,
                               'x_test': x_test,
                               'y_train': y_train,
                               'y_test': y_test,
                               'file_information': 'Indian Pines data set, each row is a sample, first columns are index values, second columns are label, and the last 200 columns are pixel information.'})

# end
# =============================================================================
</pre>




<p>读取新mat</p>
<pre>
import numpy as np
import scipy.io as sio
import tensorflow as tf


def make_one_hot(data, num_label):
    return (np.arange(num_label) == data).astype(np.integer)

def MaxMinNormalization(matrix):
    Min = np.min(matrix)
    Max = np.max(matrix)
    mat_norm = (matrix - Min) / (Max - Min)
    return mat_norm

def get_batch_data(batch_size, x_train, y_train_onehot):
    # 数据类型转换为tf.float32
    x_train = tf.cast(x_train, tf.float32)
    y_train_onehot = tf.cast(y_train_onehot, tf.float32)
    #从tensor列表中按顺序或随机抽取一个tensor
    input_queue = tf.train.slice_input_producer([x_train, y_train_onehot], shuffle=False)
    x_batch, y_batch = tf.train.batch(input_queue, batch_size=batch_size, num_threads=1, capacity=128)
    return x_batch, y_batch

def get_files():
    dataset_path = 'data_sample_new.mat'
    data_mat = sio.matlab.loadmat(dataset_path)
    data_sample = np.array(data_mat['data'])  # read data from dict
    x_train = np.array(data_mat['x_train'])  # read x_train data from dict
    x_test = np.array(data_mat['x_test'])  # read x_test data from dict
    y_train = np.array(data_mat['y_train'])  # read y_train data from dict
    y_test = np.array(data_mat['y_test'])  # read y_test data from dict

    # 归一化
    x_train = MaxMinNormalization(x_train)
    x_test = MaxMinNormalization(x_test)
    # onehot
    y_train_onehot = make_one_hot(y_train, 16)
    y_test_onehot = make_one_hot(y_test, 16)

    print('x_train.shape',x_train.shape)
    print(x_train[0])
    print('y_train_onehot.shape',y_train_onehot.shape)
    print(y_train_onehot[0])

    return x_train,y_train_onehot

def get_batch( x_train, y_train_onehot, image_W, image_H, batch_size, capacity):
    return get_batch_data(batch_size, x_train, y_train_onehot)

def main(argv=None):
    t1,t2 = get_files()
    t3,t4 = get_batch(t1,t2, 1, 200, 6, 126)
    print("Training data is converted into images!")


if __name__ == '__main__':
    main()

#然后再training.py里get_files再get_batch即可
</pre>

<h3 id="对mat文件取领域窗口····"><a href="#对mat文件取领域窗口····" class="headerlink" title="对mat文件取领域窗口····"></a>对mat文件取领域窗口····<br></h3><p>我是用matlab分割mat文件(比较方便)<br>用pytho读取分割后的文件合并制作成数据集mat,再同上面的get_files和get_batch一样</p>
<p><hr><br>matlab分割：<br><br>testt.m</p>
<p><pre><br>clc, clear, close all<br>% load the ground truth and the hyperspectral image<br>path = ‘.\Dataset\’;<br>inputs = ‘Salinas’;<br>location = [path, inputs];<br>load(location);<br>%%<br>% estimate the size of the input image<br>[height, width, bands] = size(img);<br>%Label构成的图<br>GroundImage = zeros(height, width);%145*145<br>GroundImage(GroundT(1, :)) = GroundT(2, :);%145x145 double</pre></p>
<p>X_cell = 29;<br>Y_cell = 29;</p>
<p>totalNum = floor(height/Y_cell) <em> floor(width/X_cell);%[个数,对应每个的所有像素点数]<br>OutData = zeros(totalNum,X_cell</em>Y_cell<em>bands);<br>for row=1:floor(height/Y_cell)<br>    start = (row-1)</em>Y_cell;<br>    stop = row*Y_cell;<br>    dataCol = GroundImage(start+1:stop,:,:);%height中取出对应的height衿<br>    Path_ = strcat(path,’<em>Label</em>‘,’row’,num2str(row));%strcat字符串拼接，D:\四个波段\row1’<br>    testtfunc(dataCol,width ,X_cell,Y_cell,Path_,row );<br>    row/floor(height/Y_cell)<br>end<br><br>testt.func</p>
<p><pre><br>function [  ] = testtfunc( label,width ,X_cell,Y_cell,outputPath,row )<br>ColNum = floor(width / X_cell);<br>for col = 1:ColNum<br>    start = (col-1)<em>X_cell;<br>    stop = col</em>X_cell;<br>    data = label(:,start+1:stop,:);<br>%     data(:,:,3) = dataCol(:,start+1:stop,1);</pre></p>
<pre><code>path_ =strcat(outputPath,&apos;col&apos;,num2str(col));
%inPath=strcat(outputPath,&apos;col&apos;,num2str(col),&apos;.tif&apos;);
%imwrite(uint32(data),inPath);
sum = 0;
count = 0;
result = 0;
for i = 1:X_cell
    for j = 1:Y_cell
        if(data(j,i) ~= &apos;0&apos;)
            sum = sum + data(j,i);
            count  = count + 1;
        end
    end
end

result = [sum / count];

strr = strcat(path_ , &apos;.mat&apos;)
save(strr,&apos;result&apos;);
</code></pre><p>%     imwrite(data,inPath);<br>%     tmp = reshape(data,[1 feature]);<br>%     outputData(k,:)=tmp;<br>%     k=k+1;<br>end<br><br>python的读取和制作mat:</p>
<p><pre><br>import numpy as np<br>import scipy.io as scio<br>import matplotlib.pyplot as plt<br>import math<br>from sklearn.cross_validation import train_test_split</pre></p>
<p>dataset_path = ‘./Salinas切割后数据/‘<br>label_path = ‘./Salinas切割后标签（有值的取均值）/‘</p>
<p>#dataname = ‘row1col1’</p>
<p>#data_mat = scio.loadmat(dataset_path+dataname)</p>
<p>#data = np.array(data_mat[‘data’])</p>
<p>ROW = 17<br>COL = 7<br>train_data = []<br>train_label = []</p>
<p>for i in range(ROW):<br>    for j in range(COL):<br>        dataname = ‘row’+str(i+1)+’col’+str(j+1)<br>        data_mat = scio.loadmat(dataset_path+dataname)<br>        data = data_mat[‘data’]<br>        train_data.append(data)</p>
<p>train_data = np.array(train_data)</p>
<p>for i in range(ROW):<br>    for j in range(COL):<br>        dataname = ‘_Label_row’+str(i+1)+’col’+str(j+1)#_Label_row1col1<br>        data_mat = scio.loadmat(label_path+dataname)<br>        label = data_mat[‘result’][0]<br>        train_label.append(label)</p>
<p>train_label = np.array(train_label)</p>
<p>print(“data.shape”,train_data.shape)<br>print(“data.shape”,train_label.shape)</p>
<p>x_train, x_test, y_train, y_test = train_test_split(<br>        train_data,train_label,test_size=0.1, random_state=1)</p>
<h1 id="save-data-sample"><a href="#save-data-sample" class="headerlink" title="save data_sample"></a>save data_sample</h1><p>data_sample_path = ‘./data_sample_Salinas.mat’<br>scio.savemat(data_sample_path, {‘data’: train_data,<br>                               ‘x_train’: x_train,<br>                               ‘x_test’: x_test,<br>                               ‘y_train’: y_train,<br>                               ‘y_test’: y_test,<br>                               ‘file_information’: ‘Salinas data set, each row is a sample.Made by Kevin’})<br><br>领域窗口先保存再读取制作，是比较低效且占内存的方法·····<br>领域窗口分割如果直接使用python会更好，只比matlab分割麻烦些。python可以用nump的zero创建矩阵然后解析原ma进行填充，再作分割，或者领域窗口滑动</p>

    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>花郎世纪</h4>
    <p>A lazy student.</p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?url=https://cooper111.github.io/2018/09/01/处理mat数据/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://cooper111.github.io/2018/09/01/处理mat数据/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=https://cooper111.github.io/2018/09/01/处理mat数据/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="/2018/09/01/正则化，学习率指数衰减和滑动均值模型/">
        ← 正则化，学习率指数衰减和滑动均值模型
    </a>
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2018/04/08/颜色识别，开闭/">
        Opencv颜色识别,开闭 →
    </a>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h1>

    
</div>
</main>


  
<footer class="site-footer">
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">Cooper111's Blog</a> &copy; 2014 &bull; All rights reserved.</section>
     <section class="poweredby">Proudly published with <a class="icon-ghost" href="http://zespia.tw/hexo/">Hexo</a></section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>






</body>
</html>
